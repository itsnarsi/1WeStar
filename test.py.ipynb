{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(29)\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "cudnn.benchmark = True\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchstat import stat\n",
    "from utils import  models\n",
    "from utils.data import dataset_1\n",
    "from utils.trainer_utils import parfilter\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_quality_comp(I, Iout, Enout):\n",
    "    \n",
    "    for x in ['test.png', 'test_35.jpg', 'test.flif', 'test1.png', 'test1.flif', 'test_comp.png']: \n",
    "        if os.path.exists(x):os.remove(x)\n",
    "    \n",
    "    I.save('test.png')\n",
    "    Iout.save('test_comp.png')\n",
    "    I.save('test_10.jpg', quality = 10)\n",
    "    Enout.save('test1.png')\n",
    "    \n",
    "    os.system(\"flif -e test.png test.flif\")\n",
    "    os.system(\"flif -e test1.png test1.flif\")\n",
    "    \n",
    "    print('Original Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test.png')/(I.size[0] * I.size[1])))\n",
    "    print('JPG-10% :: ' + str(8*os.path.getsize('test_10.jpg')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test.flif')/(I.size[0] * I.size[1])))\n",
    "    print('Encoded Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test1.png')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test1.flif')/(I.size[0] * I.size[1])))\n",
    "    \n",
    "def image_quality_comp2(I, Iout):\n",
    "    \n",
    "    for x in ['test.png', 'test_35.jpg', 'test.flif', 'test1.png', 'test1.flif', 'test_comp.png']: \n",
    "        if os.path.exists(x):os.remove(x)\n",
    "    \n",
    "    I.save('test.png')\n",
    "    Iout.save('test_comp.png')\n",
    "    I.save('test_10.jpg', quality = 10)\n",
    "    \n",
    "    os.system(\"flif -e test.png test.flif\")\n",
    "    \n",
    "    print('Original Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test.png')/(I.size[0] * I.size[1])))\n",
    "    print('JPG-10% :: ' + str(8*os.path.getsize('test_10.jpg')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test.flif')/(I.size[0] * I.size[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_decompress(img, model, src_fldr, dst_fldr):\n",
    "    I_org = Image.open(img).convert('RGB')\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(256*np.ceil(I.shape[0]/256) - I.shape[0])), \n",
    "                   (0, int(256*np.ceil(I.shape[1]/256) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    s_ = 256\n",
    "    d_ = 64\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It.cuda())\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    \n",
    "    Iout.save(img.replace(src_fldr, dst_fldr))\n",
    "    return Iout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression(I_org, model):\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(256*np.ceil(I.shape[0]/256) - I.shape[0])), \n",
    "                   (0, int(256*np.ceil(I.shape[1]/256) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 512//16\n",
    "    \n",
    "    c_ = s_//d_\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    Enout = np.zeros((3, I1.shape[1]//c_, I1.shape[2]//c_))\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            Xe = model.encode(It.cuda())\n",
    "            X = model.decode(Xe)\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            Xe = (Xe + 1)/2\n",
    "            Enout[:, i//c_:(i+s_)//c_, j//c_:(j+s_)//c_] = Xe.data.squeeze().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Enout = np.uint8(255 * Enout.transpose([1, 2, 0]))\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    Enout = Image.fromarray(Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "#     ssim = compare_ssim(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "    \n",
    "    print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "#     print('SSIM-PROP :: ' + \"{0:0.02f}\".format(ssim), multichannel=True)\n",
    "    \n",
    "    image_quality_comp(I_org, Iout, Enout)\n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Image.open('test_10.jpg')).copy())\n",
    "    print('PSNR-JPG10 :: ' + \"{0:0.02f}\".format(psnr))\n",
    "    \n",
    "    \n",
    "    return Iout, Enout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression2(I_org, model):\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = I_org.crop((0, 0, 256*(int(np.ceil(w/256))), 256*(np.ceil(h/256))))\n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 128\n",
    "    c_ = 8\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    Enout = np.zeros((I1.shape[1]//2, I1.shape[2]//2))\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It)\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X.data.squeeze().cpu().numpy(), 0, 1)\n",
    "            Xe = model.encode(It)\n",
    "            Xe = nn.functional.pixel_shuffle((Xe + 1)/2, 2)\n",
    "            Enout[i//2:(i+s_)//2, j//2:(j+s_)//2] = Xe.data.squeeze().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Enout = np.uint8(255 * Enout)\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    Enout = Image.fromarray(Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "#     ssim = compare_ssim(np.uint8(I_org).copy(), np.uint8(Iout).copy(), multichannel=True)\n",
    "    \n",
    "    print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "#     print('SSIM-PROP :: ' + \"{0:0.02f}\".format(ssim))\n",
    "    image_quality_comp(I_org, Iout, Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Image.open('test_35.jpg')).copy())\n",
    "    print('PSNR-JPG35 :: ' + \"{0:0.02f}\".format(psnr))\n",
    "    \n",
    "    \n",
    "    return Iout, Enout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/valid/alberto-montalesi-176097.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Image.open(img_file).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV7()\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/\"+\\\n",
    "\"QuantACTShuffleV7_exp01/checkpoint.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = True)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR-PROP :: 30.43\n",
      "Original Image :: \n",
      "PNG     :: 12.19391966250917\n",
      "JPG-10% :: 0.1823585381511372\n",
      "FLIF    :: 10.78488112160675\n",
      "Encoded Image :: \n",
      "PNG     :: 0.07856061995597946\n",
      "FLIF    :: 0.07661465975788702\n",
      "PSNR-JPG10 :: 30.35\n"
     ]
    }
   ],
   "source": [
    "Iout, Enout = perform_compression(I, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09 ms ± 10.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.54 ms ± 14.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV7()\n",
    "model.cuda()\n",
    "%timeit model.encode(torch.randn(1, 3, 256, 256).cuda())\n",
    "%timeit model.decode(torch.randn(1, 3, 32, 32).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms ± 148 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "31.3 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV7()\n",
    "%timeit model.encode(torch.randn(1, 3, 256, 256))\n",
    "%timeit model.decode(torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fldr = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/valid\"\n",
    "dst_fldr = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/model_test\"\n",
    "\n",
    "imgs = glob(src_fldr + os.sep + \"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:41<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(imgs):\n",
    "    compress_and_decompress(img, model, src_fldr, dst_fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_imgs = [img.replace(src_fldr, dst_fldr) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.competition_eval import evaluate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:36,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate2(compressed_imgs, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSNR': 29.980508816961674, 'MSSSIM': 0.968473254012289}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1363)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
