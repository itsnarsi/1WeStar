{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(29)\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "cudnn.benchmark = True\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchstat import stat\n",
    "from utils import  models\n",
    "from utils.data import dataset_1\n",
    "from utils.trainer_utils import parfilter\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = I.size\n",
    "\n",
    "p = 256\n",
    "s = 240\n",
    "\n",
    "s_w = np.arange(0, w, 240)\n",
    "if s_w[-1] + p >= w:\n",
    "    s_w[-1] = w - p\n",
    "s_h = np.arange(0, h, 240)\n",
    "if s_h[-1] + p >= h:\n",
    "    s_h[-1] = h - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  240,  480,  720,  960, 1200, 1440, 1680, 1792])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  240,  480,  720,  960, 1200, 1440, 1680, 1920])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 2048, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  240,  480,  720,  960, 1200])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 1365, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_quality_comp(I, Iout, Enout):\n",
    "    \n",
    "    for x in ['test.png', 'test_35.jpg', 'test.flif', 'test1.png', 'test1.flif', 'test_comp.png']: \n",
    "        if os.path.exists(x):os.remove(x)\n",
    "    \n",
    "    I.save('test.png')\n",
    "    Iout.save('test_comp.png')\n",
    "    I.save('test_35.jpg', quality = 35)\n",
    "    Enout.save('test1.png')\n",
    "    \n",
    "    os.system(\"flif -e test.png test.flif\")\n",
    "    os.system(\"flif -e test1.png test1.flif\")\n",
    "    \n",
    "    print('Original Image :: ')\n",
    "    print('PNG     :: ' + str(os.path.getsize('test.png')/(I.size[0] * I.size[1])))\n",
    "    print('JPG-35% :: ' + str(os.path.getsize('test_35.jpg')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(os.path.getsize('test.flif')/(I.size[0] * I.size[1])))\n",
    "    print('Encoded Image :: ')\n",
    "    print('PNG     :: ' + str(os.path.getsize('test1.png')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(os.path.getsize('test1.flif')/(I.size[0] * I.size[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot, ndarray, array\n",
    "\n",
    "def yuv2rgb(im, version='SDTV'):\n",
    "    \"\"\"\n",
    "    Convert array-like YUV image to RGB colourspace\n",
    "\n",
    "    version:\n",
    "      - 'SDTV':  ITU-R BT.601 version  (default)\n",
    "      - 'HDTV':  ITU-R BT.709 version\n",
    "    \"\"\"\n",
    "    if not im.dtype == 'uint8':\n",
    "        raise TypeError('yuv2rgb only implemented for uint8 arrays')\n",
    "\n",
    "    # clip input to the valid range\n",
    "    yuv = ndarray(im.shape)  # float64\n",
    "    yuv[:,:, 0] = im[:,:, 0].clip(16, 235).astype(yuv.dtype) - 16\n",
    "    yuv[:,:,1:] = im[:,:,1:].clip(16, 240).astype(yuv.dtype) - 128\n",
    "\n",
    "    if version.upper() == 'SDTV':\n",
    "        A = array([[1.,                 0.,  0.701            ],\n",
    "                   [1., -0.886*0.114/0.587, -0.701*0.299/0.587],\n",
    "                   [1.,  0.886,                             0.]])\n",
    "        A[:,0]  *= 255./219.\n",
    "        A[:,1:] *= 255./112.\n",
    "    elif version.upper() == 'HDTV':\n",
    "        A = array([[1.164,     0.,  1.793],\n",
    "                   [1.164, -0.213, -0.533],\n",
    "                   [1.164,  2.112,     0.]])\n",
    "    else:\n",
    "        raise Exception(\"Unrecognised version (choose 'SDTV' or 'HDTV')\")\n",
    "\n",
    "    rgb = dot(yuv, A.T)\n",
    "    result = rgb.clip(0, 255).astype('uint8')\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_decompress(img, model, src_fldr, dst_fldr):\n",
    "    I_org = Image.open(img).convert('RGB')\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(256*np.ceil(I.shape[0]/256) - I.shape[0])), \n",
    "                   (0, int(256*np.ceil(I.shape[1]/256) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I).convert('YCbCr')\n",
    "    \n",
    "    \n",
    "    s_ = 256\n",
    "    d_ = 64\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It.cuda())\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    \n",
    "    Iout = yuv2rgb(Iout, version='SDTV')\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    \n",
    "    Iout.save(img.replace(src_fldr, dst_fldr))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression(I_org, model):\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(256*np.ceil(I.shape[0]/256) - I.shape[0])), \n",
    "                   (0, int(256*np.ceil(I.shape[1]/256) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    s_ = 256\n",
    "    d_ = 64\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    Enout = np.zeros((3, I1.shape[1]//4, I1.shape[2]//4))\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It)\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            Xe = model.encode(It)\n",
    "            Xe = (Xe + 1)/2\n",
    "            Enout[:, i//4:(i+s_)//4, j//4:(j+s_)//4] = Xe.data.squeeze().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Enout = np.uint8(255 * Enout.transpose([1, 2, 0]))\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    Enout = Image.fromarray(Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "#     ssim = compare_ssim(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "    \n",
    "    print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "#     print('SSIM-PROP :: ' + \"{0:0.02f}\".format(ssim), multichannel=True)\n",
    "    \n",
    "    image_quality_comp(I_org, Iout, Enout)\n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Image.open('test_35.jpg')).copy())\n",
    "    print('PSNR-JPG35 :: ' + \"{0:0.02f}\".format(psnr))\n",
    "    \n",
    "    \n",
    "    return Iout, Enout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression2(I_org, model):\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = I_org.crop((0, 0, 256*(int(np.ceil(w/256))), 256*(np.ceil(h/256))))\n",
    "    \n",
    "    s_ = 256\n",
    "    d_ = 64\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    Enout = np.zeros((I1.shape[1]//2, I1.shape[2]//2))\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It)\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X.data.squeeze().cpu().numpy(), 0, 1)\n",
    "            Xe = model.encode(It)\n",
    "            Xe = nn.functional.pixel_shuffle((Xe + 1)/2, 2)\n",
    "            Enout[i//2:(i+s_)//2, j//2:(j+s_)//2] = Xe.data.squeeze().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Enout = np.uint8(255 * Enout)\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    Enout = Image.fromarray(Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "#     ssim = compare_ssim(np.uint8(I_org).copy(), np.uint8(Iout).copy(), multichannel=True)\n",
    "    \n",
    "    print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "#     print('SSIM-PROP :: ' + \"{0:0.02f}\".format(ssim))\n",
    "    image_quality_comp(I_org, Iout, Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Image.open('test_35.jpg')).copy())\n",
    "    print('PSNR-JPG35 :: ' + \"{0:0.02f}\".format(psnr))\n",
    "    \n",
    "    \n",
    "    return Iout, Enout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/valid/jared-erondu-21325.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Image.open(img_file).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/\"+\\\n",
    "\"QuantACTShuffleV6_exp01_YCbCr/model_best.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = models.QuantACTShuffleV3()\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/QuantACTShuffleV3_exp02/model_best.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "M.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "\n",
    "model = models.CleanImg(M)\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/CleanImg_exp01/model_best.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Iout, Enout = perform_compression(I, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.35 ms ± 26.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "12.7 ms ± 15.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "model.cuda()\n",
    "%timeit model.encode(torch.randn(8, 3, 256, 256).cuda())\n",
    "%timeit model.decode(torch.randn(8, 3, 64, 64).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.6 ms ± 295 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "374 ms ± 2.21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "%timeit model.encode(torch.randn(8, 3, 256, 256))\n",
    "%timeit model.decode(torch.randn(8, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fldr = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/valid\"\n",
    "dst_fldr = \"/media/narsi/LargeData/DATASETS/superrez/clic_2019/professional_valid/model_test\"\n",
    "\n",
    "imgs = glob(src_fldr + os.sep + \"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:49<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(imgs):\n",
    "    compress_and_decompress(img, model, src_fldr, dst_fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_imgs = [img.replace(src_fldr, dst_fldr) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.competition_eval import evaluate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:32,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate2(compressed_imgs, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSNR': 25.887533405937198, 'MSSSIM': 0.9490569508571586}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSNR': 29.974277397745475, 'MSSSIM': 0.9699624670205289}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
