{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(29)\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "cudnn.benchmark = True\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchstat import stat\n",
    "from utils import  models\n",
    "from utils.data import dataset_1\n",
    "from utils.trainer_utils import parfilter\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL.PngImagePlugin import PngImageFile, PngInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_quality_comp(I, Iout, Enout):\n",
    "    \n",
    "    for x in ['test.png', 'test_35.jpg', 'test.flif', 'test1.png', 'test1.flif', 'test_comp.png']: \n",
    "        if os.path.exists(x):os.remove(x)\n",
    "    \n",
    "    I.save('test.png')\n",
    "    Iout.save('test_comp.png')\n",
    "    I.save('test_10.jpg', quality = 10)\n",
    "    Enout.save('test1.png')\n",
    "    \n",
    "    os.system(\"flif -e test.png test.flif\")\n",
    "    os.system(\"flif -e test1.png test1.flif\")\n",
    "    \n",
    "    print('Original Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test.png')/(I.size[0] * I.size[1])))\n",
    "    print('JPG-10% :: ' + str(8*os.path.getsize('test_10.jpg')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test.flif')/(I.size[0] * I.size[1])))\n",
    "    print('Encoded Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test1.png')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test1.flif')/(I.size[0] * I.size[1])))\n",
    "    \n",
    "def image_quality_comp2(I, Iout):\n",
    "    \n",
    "    for x in ['test.png', 'test_35.jpg', 'test.flif', 'test1.png', 'test1.flif', 'test_comp.png']: \n",
    "        if os.path.exists(x):os.remove(x)\n",
    "    \n",
    "    I.save('test.png')\n",
    "    Iout.save('test_comp.png')\n",
    "    I.save('test_10.jpg', quality = 10)\n",
    "    \n",
    "    os.system(\"flif -e test.png test.flif\")\n",
    "    \n",
    "    print('Original Image :: ')\n",
    "    print('PNG     :: ' + str(8*os.path.getsize('test.png')/(I.size[0] * I.size[1])))\n",
    "    print('JPG-10% :: ' + str(8*os.path.getsize('test_10.jpg')/(I.size[0] * I.size[1])))\n",
    "    print('FLIF    :: ' + str(8*os.path.getsize('test.flif')/(I.size[0] * I.size[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_decompress(img, model, src_fldr, dst_fldr):\n",
    "    I_org = Image.open(img).convert('RGB')\n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 128\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(s_*np.ceil(I.shape[0]/s_) - I.shape[0])), \n",
    "                   (0, int(s_*np.ceil(I.shape[1]/s_) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It.cuda())\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    \n",
    "    Iout.save(img.replace(src_fldr, dst_fldr))\n",
    "    return Iout\n",
    "\n",
    "def compress_and_decompress2(img, model):\n",
    "    I_org = Image.open(img).convert('RGB')\n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 128\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(s_*np.ceil(I.shape[0]/s_) - I.shape[0])), \n",
    "                   (0, int(s_*np.ceil(I.shape[1]/s_) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model(It.cuda())\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    \n",
    "    \n",
    "    return Iout\n",
    "\n",
    "def compress2(img, model):\n",
    "    I_org = Image.open(img).convert('RGB')\n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 128\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(s_*np.ceil(I.shape[0]/s_) - I.shape[0])), \n",
    "                   (0, int(s_*np.ceil(I.shape[1]/s_) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Eout = []\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            X = model.encode(It.cuda())\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Eout.append(X)\n",
    "            \n",
    "    return np.concatenate(Eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_compression(I_org, model):\n",
    "    \n",
    "    w, h = I_org.size\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(256*np.ceil(I.shape[0]/256) - I.shape[0])), \n",
    "                   (0, int(256*np.ceil(I.shape[1]/256) - I.shape[1])), \n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "    \n",
    "    \n",
    "    s_ = 512\n",
    "    d_ = 512//16\n",
    "    \n",
    "    c_ = s_//d_\n",
    "    \n",
    "    I1 = np.float32(I)#[:256, :256, :]\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "    Iout = np.zeros_like(I1)\n",
    "    Enout = np.zeros((3, I1.shape[1]//c_, I1.shape[2]//c_))\n",
    "    for i in range(0, I1.shape[1], s_):\n",
    "        for j in range(0, I1.shape[2], s_):\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, i:i+s_, j:j+s_], 0))/255.0\n",
    "            Xe = model.encode(It.cuda())\n",
    "            X = model.decode(Xe)\n",
    "            X = X.data.squeeze().cpu().numpy()\n",
    "            Iout[:, i:i+s_, j:j+s_] = np.clip(X, 0, 1)\n",
    "            Xe = (Xe + 1)/2\n",
    "            Enout[:, i//c_:(i+s_)//c_, j//c_:(j+s_)//c_] = Xe.data.squeeze().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Enout = np.uint8(255 * Enout.transpose([1, 2, 0]))\n",
    "    \n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "    Enout = Image.fromarray(Enout)\n",
    "    \n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "#     ssim = compare_ssim(np.uint8(I_org).copy(), np.uint8(Iout).copy())\n",
    "    \n",
    "    print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "#     print('SSIM-PROP :: ' + \"{0:0.02f}\".format(ssim), multichannel=True)\n",
    "    \n",
    "    image_quality_comp(I_org, Iout, Enout)\n",
    "    psnr = compare_psnr(np.uint8(I_org).copy(), np.uint8(Image.open('test_10.jpg')).copy())\n",
    "    print('PSNR-JPG10 :: ' + \"{0:0.02f}\".format(psnr))\n",
    "    \n",
    "    \n",
    "    return Iout, Enout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(I_org, model):\n",
    "\n",
    "    e_ = 512\n",
    "    c_ = 4\n",
    "    d_ = e_ // c_\n",
    "    pad_ = 4\n",
    "\n",
    "    w, h = I_org.size\n",
    "\n",
    "    comp_w_new = np.ceil(w/c_)\n",
    "    comp_h_new = np.ceil(h/c_)\n",
    "\n",
    "    new_w = int(e_ * np.ceil(w/e_))\n",
    "    new_h = int(e_ * np.ceil(h/e_))\n",
    "\n",
    "    com_w = new_w // c_\n",
    "    com_h = new_h // c_\n",
    "\n",
    "    I = np.uint8(I_org).copy()\n",
    "    I = np.pad(I, ((0, int(new_h - h)),\n",
    "                   (0, int(new_w - w)),\n",
    "                   (0, 0)), mode = \"reflect\")\n",
    "    I = Image.fromarray(I)\n",
    "\n",
    "\n",
    "    I1 = np.float32(I)/255.0\n",
    "    I1 = np.transpose(I1, [2, 0, 1])\n",
    "\n",
    "    Enout = np.zeros((3, com_h, com_w))\n",
    "    Enout_w = np.zeros((3, com_h, com_w))\n",
    "    for i in list(np.arange(0, new_h, e_)):\n",
    "        for j in list(np.arange(0, new_w, e_)):\n",
    "            if i == 0:\n",
    "                x1 = int(i)\n",
    "                x2 = int((i + e_) + (pad_*2*c_))\n",
    "            else:\n",
    "                x1 = int(i - (pad_*c_))\n",
    "                x2 = int((i + e_) + (pad_*c_))\n",
    "\n",
    "            if j == 0:\n",
    "                y1 = int(j)\n",
    "                y2 = int((j + e_) + (pad_*2*c_))\n",
    "            else:\n",
    "                y1 = int(j - (pad_*c_))\n",
    "                y2 = int((j + e_) + (pad_*c_))\n",
    "            It = torch.from_numpy(np.expand_dims(I1[:, x1:x2, y1:y2], 0))\n",
    "            Xe = model.encode(It.cuda())\n",
    "            Xe = (Xe + 1.0)/2.0\n",
    "            Enout[:, x1//c_:x2//c_, y1//c_:y2//c_] += Xe.data.squeeze().cpu().numpy()\n",
    "            Enout_w[:, x1//c_:x2//c_, y1//c_:y2//c_] += 1.0\n",
    "\n",
    "    Enout = Enout/Enout_w\n",
    "    Enout = np.uint8(255 * Enout.transpose([1, 2, 0]))\n",
    "\n",
    "    Enout = Image.fromarray(Enout).crop((0, 0, comp_w_new, comp_h_new))\n",
    "\n",
    "    return Enout\n",
    "\n",
    "\n",
    "def decompress(EnIn, model, w, h):\n",
    "\n",
    "    e_ = 256\n",
    "    c_ = 4\n",
    "    d_ = e_ // c_\n",
    "    pad_ = 4\n",
    "\n",
    "#     w, h = int(EnIn.text['w']), int(EnIn.text['h'])\n",
    "\n",
    "    comp_w_new = np.ceil(w/c_)\n",
    "    comp_h_new = np.ceil(h/c_)\n",
    "\n",
    "    new_w = int(e_ * np.ceil(w/e_))\n",
    "    new_h = int(e_ * np.ceil(h/e_))\n",
    "\n",
    "    com_w = new_w // c_\n",
    "    com_h = new_h // c_\n",
    "\n",
    "\n",
    "    Iout = np.zeros((3,new_h,new_w), dtype = np.float32)\n",
    "    Iout_w = np.zeros((3,new_h,new_w), dtype = np.float32)\n",
    "\n",
    "    EnIn = np.uint8(EnIn).copy()\n",
    "    EnIn = np.pad(EnIn, ((0, int(com_h - EnIn.shape[0])),\n",
    "                         (0, int(com_w - EnIn.shape[1])),\n",
    "                         (0, 0)), mode = \"reflect\")\n",
    "\n",
    "\n",
    "    EnIn = np.float32(EnIn)/255.0\n",
    "    EnIn = np.transpose(EnIn, [2, 0, 1])\n",
    "    for i in list(np.arange(0, com_h, d_)):\n",
    "        for j in list(np.arange(0, com_w, d_)):\n",
    "\n",
    "            if i == 0:\n",
    "                x1 = int(i)\n",
    "                x2 = int((i + d_) + pad_*2)\n",
    "            else:\n",
    "                x1 = int(i - pad_)\n",
    "                x2 = int((i + d_) + pad_)\n",
    "\n",
    "            if j == 0:\n",
    "                y1 = int(j)\n",
    "                y2 = int((j + d_) + pad_*2)\n",
    "            else:\n",
    "                y1 = int(j - pad_)\n",
    "                y2 = int((j + d_) + pad_)\n",
    "\n",
    "            It = torch.from_numpy(np.expand_dims(EnIn[:, x1:x2, y1:y2], 0))\n",
    "            It = It * 2.0 - 1.0\n",
    "            Xe = model.decode(It.cuda()).data.squeeze().cpu()\n",
    "\n",
    "            Iout[:, x1*c_:x2*c_, y1*c_:y2*c_] += np.clip(Xe.numpy(), 0, 1)\n",
    "            Iout_w[:, x1*c_:x2*c_, y1*c_:y2*c_] += 1.0\n",
    "\n",
    "    Iout = Iout/Iout_w\n",
    "\n",
    "    Iout = np.uint8(255 * Iout.transpose([1, 2, 0]))\n",
    "    Iout = Image.fromarray(Iout).crop((0, 0, w, h))\n",
    "\n",
    "    return Iout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = \"/media/cibitaw1/DATA/super_rez/professional_valid/valid/jared-erondu-21325.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Image.open(img_file).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "check_point_file = \"/media/cibitaw1/DATA/SP2020/compressACT/weights/\"+\\\n",
    "\"QuantACTShuffleV6_exp01/checkpoint.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = models.QuantACTShuffleV3()\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/QuantACTShuffleV3_exp02/model_best.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "M.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "\n",
    "model = models.CleanImg(M)\n",
    "check_point_file = \"/media/narsi/LargeData/SP_2020/compressACT/weights/CleanImg_exp01/model_best.pth.tar\"\n",
    "checkpoint = torch.load(check_point_file)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR-PROP :: 30.43\n",
      "Original Image :: \n",
      "PNG     :: 12.19391966250917\n",
      "JPG-10% :: 0.1823585381511372\n",
      "FLIF    :: 10.78488112160675\n",
      "Encoded Image :: \n",
      "PNG     :: 0.07856061995597946\n",
      "FLIF    :: 0.07661465975788702\n",
      "PSNR-JPG10 :: 30.35\n"
     ]
    }
   ],
   "source": [
    "Iout, Enout = perform_compression(I, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iout = compress_and_decompress2(img_file, model)\n",
    "image_quality_comp(I, Iout)\n",
    "psnr = compare_psnr(np.uint8(I).copy(), np.uint8(Iout).copy())\n",
    "print('PSNR-PROP :: ' + \"{0:0.02f}\".format(psnr))\n",
    "psnr = compare_psnr(np.uint8(I).copy(), np.uint8(Image.open('test_10.jpg')).copy())\n",
    "print('PSNR-JPG35 :: ' + \"{0:0.02f}\".format(psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eout = compress2(img_file, model)\n",
    "eout = np.uint8(eout == 1).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eout)/(I.size[0] * I.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = plt.hist(eout, bins = 2)\n",
    "print(dist[0]/np.sum(dist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from range_coder import RangeEncoder, RangeDecoder, prob_to_cum_freq\n",
    "\n",
    "data = list(eout.tolist())\n",
    "prob = list(dist[0]/np.sum(dist[0]))\n",
    "\n",
    "# convert probabilities to cumulative integer frequency table\n",
    "cumFreq = prob_to_cum_freq(prob, resolution=128)\n",
    "\n",
    "filepath = 'test.dat'\n",
    "\n",
    "# encode data\n",
    "encoder = RangeEncoder(filepath)\n",
    "encoder.encode(data, cumFreq)\n",
    "encoder.close()\n",
    "\n",
    "# decode data\n",
    "decoder = RangeDecoder(filepath)\n",
    "dataRec = decoder.decode(len(data), cumFreq)\n",
    "decoder.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(os.path.getsize('test.dat')*8)/(I.size[0] * I.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.69 ms ± 40 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.66 ms ± 16.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "model.cuda()\n",
    "%timeit model.encode(torch.randn(1, 3, 256, 256).cuda())\n",
    "%timeit model.decode(torch.randn(1, 3, 64, 64).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ms ± 494 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "61.8 ms ± 1.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "model = models.QuantACTShuffleV6()\n",
    "%timeit model.encode(torch.randn(1, 3, 256, 256))\n",
    "%timeit model.decode(torch.randn(1, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_fldr = \"/media/cibitaw1/DATA/super_rez/professional_valid/valid\"\n",
    "# imgs = glob(src_fldr + os.sep + \"*.png\")\n",
    "src_fldr = \"/media/cibitaw1/DATA/super_rez/mobile_valid/valid\"\n",
    "imgs = glob(src_fldr + os.sep + \"*.png\")\n",
    "dst_fldr = \"/media/cibitaw1/DATA/super_rez/comp_test/decompressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img in tqdm(imgs):\n",
    "    compress_and_decompress(img, model, src_fldr, dst_fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_imgs = [img.replace(src_fldr, dst_fldr) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.competition_eval import evaluate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [04:37,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate2(compressed_imgs, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSNR': 29.003067337589883, 'MSSSIM': 0.9377486467526164}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PSNR': 28.578408862459263, 'MSSSIM': 0.9368299242025995}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(29.003067337589883+28.83994787307876)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.9736846666083886+0.9705319931942877)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpeg2000_comp = \"bpgenc\"\n",
    "jpeg2000_decomp = \"bpgdec\"\n",
    "src_enco_img = \"/home/cibitaw1/local/1WeStar/test_en.png\"\n",
    "src_jp2_img = \"/home/cibitaw1/local/1WeStar/test_en_comp.bpg\"\n",
    "src_dejp2_img = \"/home/cibitaw1/local/1WeStar/test_en_decomp.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enout = compress(I, model)\n",
    "metadata = PngInfo()\n",
    "metadata.add_text(\"w\", str(I.size[0]))\n",
    "metadata.add_text(\"h\", str(I.size[1]))\n",
    "Enout.save(\"test_en.png\", pnginfo=metadata)\n",
    "Enout = Image.open(\"test_en.png\")\n",
    "\n",
    "# Iout = decompress(Enout, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 33.472688064350734, '0.11261446886446887']\n",
      "[29, 32.367402798669254, '0.06944826007326008']\n"
     ]
    }
   ],
   "source": [
    "compress_ = []\n",
    "for i in [25, 29]:\n",
    "    os.system(jpeg2000_comp + \" -m 9 -f 444 -q \" + str(i) + \" \" + src_enco_img + \" -o \" + src_jp2_img)#-i + \" -r \" + str(i) + \" -b  64,64\"\n",
    "    #-q \" + str(i) + \" -m 6\n",
    "    os.system(jpeg2000_decomp + \" \" + src_jp2_img + \" -o \" + src_dejp2_img)#-i \n",
    "    Enout_ = Image.open(src_dejp2_img)\n",
    "    Iout = decompress(Enout_, model, I.size[0], I.size[1])\n",
    "    p_ = compare_psnr(np.uint8(I).copy(), np.uint8(Iout).copy())\n",
    "    bpp_ = str(8*os.path.getsize(src_jp2_img)/(I.size[0] * I.size[1]))\n",
    "    compress_.append([i, p_, bpp_])\n",
    "    print([i, p_, bpp_])\n",
    "    Iout.save(\"test_q_\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sewar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9530768884465469+0j)\n",
      "(0.9303436753855934+0j)\n"
     ]
    }
   ],
   "source": [
    "for i in [25, 29]:\n",
    "    print(sewar.msssim(np.uint8(I).copy(), np.uint8(Image.open(\"test_q_\" + str(i) + \".png\")).copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
